{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrS8CaLPpjyWldyxxw1krI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bolby0216/myrepository2/blob/master/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k-BR9ppu42o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tensorflow 1.13.1 버전을 설치합니다.\n",
        "!pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFjaqk6hvF2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#그에 맞는 CUDA 버전도 설치해줍니다.\n",
        "!apt-get --purge remove \"*cublas*\" \"cuda*\"\n",
        "!reboot\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "!apt install cuda-10-0\n",
        "!reboot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcAsUxHAuaAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ipython-autotime\n",
        " \n",
        "%load_ext autotime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF4GC6rwjfS1",
        "colab_type": "code",
        "outputId": "12f77851-17b0-4fa8-b020-b603b4db6d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "\n",
        "#MNIST 데이터 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "dddd = x_test\n",
        "\n",
        "#test set에서 validation set을 10000개 만큼 분리해줍니다. 이는 validation accuracy가 진전되지 않을때 overfitting을 막기위해 사용됩니다.\n",
        "x_val  = x_train[50000:60000]\n",
        "x_train = x_train[0:50000]\n",
        "y_val  = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"train data has \" + str(x_train.shape[0]) + \" samples\")\n",
        "print(\"every train data is \" + str(x_train.shape[1]) \n",
        "      + \" * \" + str(x_train.shape[2]) + \" image\")\n",
        "\n",
        "print(\"validation data has \" + str(x_val.shape[0]) + \" samples\")\n",
        "print(\"every train data is \" + str(x_val.shape[1]) \n",
        "      + \" * \" + str(x_train.shape[2]) + \" image\")\n",
        "\n",
        "print(\"test data has \" + str(x_test.shape[0]) + \" samples\")\n",
        "print(\"every test data is \" + str(x_test.shape[1]) \n",
        "      + \" * \" + str(x_test.shape[2]) + \" image\")\n",
        "\n",
        "#flattening을 해줍니다\n",
        "x_train = x_train.reshape(50000, 784)\n",
        "x_val = x_val.reshape(10000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "#정규화를 해줍니다\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "gray_scale = 255\n",
        "x_train /= gray_scale\n",
        "x_val /= gray_scale\n",
        "x_test /= gray_scale\n",
        "\n",
        "#one hot encoding\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "train data has 50000 samples\n",
            "every train data is 28 * 28 image\n",
            "validation data has 10000 samples\n",
            "every train data is 28 * 28 image\n",
            "test data has 10000 samples\n",
            "every test data is 28 * 28 image\n",
            "(50000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxjpxh6kuzJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5lP-lQ7wV3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp(x):\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "    # hidden layer1\n",
        "    w1 = tf.Variable(tf.random_uniform([784,256]))\n",
        "    b1 = tf.Variable(tf.zeros([256]))\n",
        "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
        "    h1 = tf.nn.dropout(h1, keep_prob=0.7)\n",
        "    # hidden layer2\n",
        "    w2 = tf.Variable(tf.random_uniform([256,128]))\n",
        "    b2 = tf.Variable(tf.zeros([128]))\n",
        "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
        "    h2 = tf.nn.dropout(h2, keep_prob=0.7)\n",
        "    # output layer\n",
        "    w3 = tf.Variable(tf.random_uniform([128,10]))\n",
        "    b3 = tf.Variable(tf.zeros([10]))\n",
        "    logits= tf.matmul(h2, w3) + b3\n",
        "    \n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIvyxspjwbqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits = mlp(x)\n",
        "\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "    logits=logits, labels=y))\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw4s1SRewm_L",
        "colab_type": "code",
        "outputId": "c4f1539a-830d-41d5-b635-7351ee6f9375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 초기화\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# 하이퍼 파라미터\n",
        "epoch_cnt = 100 #학습횟수\n",
        "batch_size = 1000 #학습률\n",
        "iteration = len(x_train) // batch_size\n",
        "\n",
        "#graph x,y\n",
        "graph_x = list(range(epoch_cnt))\n",
        "graph_y = []\n",
        "\n",
        "start = time.time()\n",
        "# 훈련 시작\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(epoch_cnt):\n",
        "        avg_loss = 0.\n",
        "        start = 0; end = batch_size\n",
        "        \n",
        "        for i in range(iteration):\n",
        "            _, loss = sess.run([train_op, loss_op], \n",
        "                               feed_dict={x: x_train[start: end], y: y_train[start: end]})\n",
        "            start += batch_size; end += batch_size\n",
        "            # 평균 loss 계산\n",
        "            avg_loss += loss / iteration\n",
        "            \n",
        "        # 모델 validate\n",
        "        preds = tf.nn.softmax(logits)  #logit값에 활성화함수 softmax를 적용\n",
        "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
        "        # 정확도 계산\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "        cur_val_acc = accuracy.eval({x: x_val, y: y_val})\n",
        "        graph_y.append(cur_val_acc)\n",
        "        #\n",
        "        preds = tf.nn.softmax(logits)  #logit값에 활성화함수 softmax를 적용\n",
        "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "        train_accuracy = accuracy.eval({x: x_train, y: y_train})\n",
        "        #\n",
        "        print(\"epoch: \"+str(epoch)+\", train accuracy: \"+ str(train_accuracy) +\", validation accuracy: \" \n",
        "              + str(cur_val_acc) +', loss: '+str(avg_loss))\n",
        "    \n",
        "    # 모델 테스트\n",
        "    preds = tf.nn.softmax(logits)  # Apply softmax to logits\n",
        "    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
        "    # 정확도 계산\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    print(\"[Test Accuracy] :\", accuracy.eval({x: x_test, y: y_test}))\n",
        "\n",
        "    # 테스트를 위해 임의의 MNIST 이미지를 넣어줍니다\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "    prediction=tf.argmax(preds,1)\n",
        "    predint = prediction.eval(feed_dict={x: [x_test[1]],keep_prob: 1.0}, session=sess)\n",
        "    # 예측값을 출력\n",
        "    print(\"[Predicted Number] :\", predint[0])\n",
        "\n",
        "    # 예측값이 맞는지 비교하기 위해 해당 MNIST 이미지를 보여줍니다\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(dddd[1], cmap=plt.cm.binary)\n",
        "\n",
        "    # validation accuracy의 지표를 그래프로 나타냅니다\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(graph_x, graph_y)\n",
        "    plt.show()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, train accuracy: 0.10702, validation accuracy: 0.1111, loss: 12580.708217773436\n",
            "epoch: 1, train accuracy: 0.13792, validation accuracy: 0.1359, loss: 300.71272068023694\n",
            "epoch: 2, train accuracy: 0.14636, validation accuracy: 0.1469, loss: 2.2257541847229\n",
            "epoch: 3, train accuracy: 0.19704, validation accuracy: 0.21, loss: 2.18338020324707\n",
            "epoch: 4, train accuracy: 0.22654, validation accuracy: 0.2335, loss: 2.1216078615188594\n",
            "epoch: 5, train accuracy: 0.25292, validation accuracy: 0.2666, loss: 2.0508502388000487\n",
            "epoch: 6, train accuracy: 0.28436, validation accuracy: 0.2963, loss: 1.994020414352417\n",
            "epoch: 7, train accuracy: 0.30868, validation accuracy: 0.3266, loss: 1.929584820270538\n",
            "epoch: 8, train accuracy: 0.3323, validation accuracy: 0.3358, loss: 1.865729656219483\n",
            "epoch: 9, train accuracy: 0.34752, validation accuracy: 0.3562, loss: 1.8163259100914002\n",
            "epoch: 10, train accuracy: 0.36494, validation accuracy: 0.3703, loss: 1.775267539024353\n",
            "epoch: 11, train accuracy: 0.37932, validation accuracy: 0.3867, loss: 1.7297105646133428\n",
            "epoch: 12, train accuracy: 0.38868, validation accuracy: 0.3956, loss: 1.7015641307830816\n",
            "epoch: 13, train accuracy: 0.40688, validation accuracy: 0.4148, loss: 1.666195471286774\n",
            "epoch: 14, train accuracy: 0.42466, validation accuracy: 0.4259, loss: 1.6250626420974732\n",
            "epoch: 15, train accuracy: 0.43682, validation accuracy: 0.4444, loss: 1.5924167394638058\n",
            "epoch: 16, train accuracy: 0.45066, validation accuracy: 0.4607, loss: 1.5659387612342834\n",
            "epoch: 17, train accuracy: 0.46662, validation accuracy: 0.4748, loss: 1.522046408653259\n",
            "epoch: 18, train accuracy: 0.48566, validation accuracy: 0.4941, loss: 1.4859288048744206\n",
            "epoch: 19, train accuracy: 0.508, validation accuracy: 0.5128, loss: 1.4374298334121702\n",
            "epoch: 20, train accuracy: 0.52244, validation accuracy: 0.53, loss: 1.398018107414246\n",
            "epoch: 21, train accuracy: 0.53534, validation accuracy: 0.5442, loss: 1.3612665367126464\n",
            "epoch: 22, train accuracy: 0.5524, validation accuracy: 0.5581, loss: 1.3268508672714232\n",
            "epoch: 23, train accuracy: 0.56616, validation accuracy: 0.5792, loss: 1.2839815831184387\n",
            "epoch: 24, train accuracy: 0.58432, validation accuracy: 0.5887, loss: 1.2686617636680606\n",
            "epoch: 25, train accuracy: 0.60718, validation accuracy: 0.6123, loss: 1.2249967312812808\n",
            "epoch: 26, train accuracy: 0.62548, validation accuracy: 0.625, loss: 1.1822584748268123\n",
            "epoch: 27, train accuracy: 0.642, validation accuracy: 0.6554, loss: 1.1450581645965574\n",
            "epoch: 28, train accuracy: 0.65106, validation accuracy: 0.6571, loss: 1.109157773256302\n",
            "epoch: 29, train accuracy: 0.6611, validation accuracy: 0.6694, loss: 1.0883462643623347\n",
            "epoch: 30, train accuracy: 0.67002, validation accuracy: 0.6772, loss: 1.067455161809921\n",
            "epoch: 31, train accuracy: 0.6786, validation accuracy: 0.6821, loss: 1.0365989792346957\n",
            "epoch: 32, train accuracy: 0.6847, validation accuracy: 0.692, loss: 1.0195527946949006\n",
            "epoch: 33, train accuracy: 0.6897, validation accuracy: 0.6978, loss: 0.9996892714500427\n",
            "epoch: 34, train accuracy: 0.69998, validation accuracy: 0.7039, loss: 0.9824671483039857\n",
            "epoch: 35, train accuracy: 0.70372, validation accuracy: 0.713, loss: 0.9594984829425813\n",
            "epoch: 36, train accuracy: 0.7113, validation accuracy: 0.7205, loss: 0.9430731725692748\n",
            "epoch: 37, train accuracy: 0.7166, validation accuracy: 0.724, loss: 0.920207804441452\n",
            "epoch: 38, train accuracy: 0.73048, validation accuracy: 0.7265, loss: 0.9048819553852082\n",
            "epoch: 39, train accuracy: 0.73148, validation accuracy: 0.7417, loss: 0.8801449501514436\n",
            "epoch: 40, train accuracy: 0.73918, validation accuracy: 0.7421, loss: 0.8610600244998932\n",
            "epoch: 41, train accuracy: 0.74438, validation accuracy: 0.7475, loss: 0.8530581390857696\n",
            "epoch: 42, train accuracy: 0.7488, validation accuracy: 0.7524, loss: 0.8297669064998628\n",
            "epoch: 43, train accuracy: 0.75372, validation accuracy: 0.7524, loss: 0.8161954331398009\n",
            "epoch: 44, train accuracy: 0.7559, validation accuracy: 0.7615, loss: 0.809261964559555\n",
            "epoch: 45, train accuracy: 0.76188, validation accuracy: 0.7605, loss: 0.7940444457530977\n",
            "epoch: 46, train accuracy: 0.76314, validation accuracy: 0.771, loss: 0.7803566598892213\n",
            "epoch: 47, train accuracy: 0.76794, validation accuracy: 0.7759, loss: 0.7725873816013337\n",
            "epoch: 48, train accuracy: 0.77456, validation accuracy: 0.7767, loss: 0.7511701703071595\n",
            "epoch: 49, train accuracy: 0.77764, validation accuracy: 0.7818, loss: 0.7461165988445283\n",
            "epoch: 50, train accuracy: 0.78274, validation accuracy: 0.784, loss: 0.736078554391861\n",
            "epoch: 51, train accuracy: 0.78824, validation accuracy: 0.7888, loss: 0.722062885761261\n",
            "epoch: 52, train accuracy: 0.79076, validation accuracy: 0.7954, loss: 0.7099949955940245\n",
            "epoch: 53, train accuracy: 0.79526, validation accuracy: 0.799, loss: 0.7015579032897947\n",
            "epoch: 54, train accuracy: 0.79922, validation accuracy: 0.8031, loss: 0.686074595451355\n",
            "epoch: 55, train accuracy: 0.8077, validation accuracy: 0.8079, loss: 0.6798582541942597\n",
            "epoch: 56, train accuracy: 0.80838, validation accuracy: 0.8112, loss: 0.6685765051841736\n",
            "epoch: 57, train accuracy: 0.81198, validation accuracy: 0.8185, loss: 0.6629102587699893\n",
            "epoch: 58, train accuracy: 0.81602, validation accuracy: 0.8191, loss: 0.6464332914352419\n",
            "epoch: 59, train accuracy: 0.82112, validation accuracy: 0.817, loss: 0.6381878751516344\n",
            "epoch: 60, train accuracy: 0.81924, validation accuracy: 0.8258, loss: 0.6203265857696534\n",
            "epoch: 61, train accuracy: 0.82426, validation accuracy: 0.8269, loss: 0.6197615325450897\n",
            "epoch: 62, train accuracy: 0.82754, validation accuracy: 0.8291, loss: 0.6120079630613328\n",
            "epoch: 63, train accuracy: 0.8292, validation accuracy: 0.8268, loss: 0.6134855633974075\n",
            "epoch: 64, train accuracy: 0.83202, validation accuracy: 0.8319, loss: 0.604893797636032\n",
            "epoch: 65, train accuracy: 0.83126, validation accuracy: 0.8337, loss: 0.5884949278831481\n",
            "epoch: 66, train accuracy: 0.83316, validation accuracy: 0.8345, loss: 0.5794074445962908\n",
            "epoch: 67, train accuracy: 0.83462, validation accuracy: 0.8374, loss: 0.5842141574621201\n",
            "epoch: 68, train accuracy: 0.83766, validation accuracy: 0.8422, loss: 0.5795315659046175\n",
            "epoch: 69, train accuracy: 0.84072, validation accuracy: 0.8386, loss: 0.5638082259893418\n",
            "epoch: 70, train accuracy: 0.84202, validation accuracy: 0.8387, loss: 0.5642763125896456\n",
            "epoch: 71, train accuracy: 0.84588, validation accuracy: 0.8447, loss: 0.5597514122724533\n",
            "epoch: 72, train accuracy: 0.84612, validation accuracy: 0.8469, loss: 0.5491786891222\n",
            "epoch: 73, train accuracy: 0.84744, validation accuracy: 0.8499, loss: 0.5550544804334643\n",
            "epoch: 74, train accuracy: 0.84858, validation accuracy: 0.8498, loss: 0.5427270203828812\n",
            "epoch: 75, train accuracy: 0.84884, validation accuracy: 0.8444, loss: 0.5344736814498903\n",
            "epoch: 76, train accuracy: 0.85198, validation accuracy: 0.8482, loss: 0.5333670830726622\n",
            "epoch: 77, train accuracy: 0.85304, validation accuracy: 0.8482, loss: 0.5271543091535567\n",
            "epoch: 78, train accuracy: 0.85128, validation accuracy: 0.8506, loss: 0.5248311764001846\n",
            "epoch: 79, train accuracy: 0.85932, validation accuracy: 0.8524, loss: 0.5167924576997759\n",
            "epoch: 80, train accuracy: 0.8566, validation accuracy: 0.8516, loss: 0.5150058841705323\n",
            "epoch: 81, train accuracy: 0.85984, validation accuracy: 0.8603, loss: 0.5069359499216078\n",
            "epoch: 82, train accuracy: 0.85962, validation accuracy: 0.858, loss: 0.5044895809888841\n",
            "epoch: 83, train accuracy: 0.85974, validation accuracy: 0.8567, loss: 0.499307717680931\n",
            "epoch: 84, train accuracy: 0.86618, validation accuracy: 0.8622, loss: 0.4893391036987304\n",
            "epoch: 85, train accuracy: 0.86484, validation accuracy: 0.8595, loss: 0.4876508605480193\n",
            "epoch: 86, train accuracy: 0.86796, validation accuracy: 0.8592, loss: 0.48022462010383615\n",
            "epoch: 87, train accuracy: 0.86748, validation accuracy: 0.8682, loss: 0.4781349408626558\n",
            "epoch: 88, train accuracy: 0.86974, validation accuracy: 0.8638, loss: 0.47354963719844817\n",
            "epoch: 89, train accuracy: 0.87202, validation accuracy: 0.8636, loss: 0.4691054874658584\n",
            "epoch: 90, train accuracy: 0.8745, validation accuracy: 0.8647, loss: 0.46252931594848634\n",
            "epoch: 91, train accuracy: 0.87726, validation accuracy: 0.8728, loss: 0.455918720960617\n",
            "epoch: 92, train accuracy: 0.8792, validation accuracy: 0.87, loss: 0.4460057252645491\n",
            "epoch: 93, train accuracy: 0.87822, validation accuracy: 0.8704, loss: 0.44182293772697456\n",
            "epoch: 94, train accuracy: 0.8804, validation accuracy: 0.8737, loss: 0.43897203743457797\n",
            "epoch: 95, train accuracy: 0.88204, validation accuracy: 0.8709, loss: 0.436237397789955\n",
            "epoch: 96, train accuracy: 0.88482, validation accuracy: 0.8752, loss: 0.43236653208732595\n",
            "epoch: 97, train accuracy: 0.88372, validation accuracy: 0.8752, loss: 0.42652091562747946\n",
            "epoch: 98, train accuracy: 0.89058, validation accuracy: 0.8771, loss: 0.4150612306594849\n",
            "epoch: 99, train accuracy: 0.8915, validation accuracy: 0.8795, loss: 0.41984081864357004\n",
            "[Test Accuracy] : 0.8746\n",
            "[Predicted Number] : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXyV5Z338c+PhE2CbEGIQAggIosKGnctOG5gLaidIthanMdncPrUGW316VhrbYenttaqnfY1TFutVG21ijujtGgt1rpRAiJbWCICAbMDISwh2+/549zQQ3JCQnKW5Jzv+/Xilftc5zr3/TuH5Jcr130t5u6IiEjn1yXRAYiISHQooYuIJAkldBGRJKGELiKSJJTQRUSSRHqiAxBJBpmZmZ6Tk5PoMCRJrVixotzdB7ZUTwldJApycnLIy8tLdBiSpMxsW2vqqctFUoqZTTWzjWZWYGZ3R3h+uJm9ZWarzextMxuaiDhF2kIJXVKGmaUB84FpwDhgtpmNa1TtIeApdz8DmAf8KL5RirSdErqkknOBAnff4u41wLPAjEZ1xgF/Do6XRnhepMNSQpdUMgQoDHu8IygL9zFwfXB8HdDbzAZEOpmZzTWzPDPLKysri3qwIsdLCV3kaHcBk83sI2AysBOoj1TR3R9191x3zx04sMUBCCIxp1Eukkp2AsPCHg8Nyo5w988IWuhmlgF80d33xC1CkXZQC11SyXJgtJmNMLNuwCxgUXgFM8s0s8M/F98GFsQ5RpE2U0KXlOHudcBtwBIgH1jo7uvMbJ6ZTQ+qTQE2mtkmYBBwf0KClZSx71AdC979lHc2tf8+jLpcJKW4+2JgcaOy+8KOXwBeiHdckjoaGpwl64rZdaCG1YWVLF5TRNWhOuZcMJzPndq+ezFK6CIiUba3upa7X1zNWdn9uPr0LFZs280jb24iM6MbPbulH2mN9+qWxlUTBvPVC3KYOKxvu6+rhC4i0g5/3VzGZ3sOMjN3GGYGwP2v5bN4TTGL1xTzg9fzAThtcG927D5IWdUh/mP6eKZOGEyfnl3p0TUtarEooYuIHIf6BqeLgZlRVnWI//P0Sqqq61i6oYxzRvTn0/J9PJdXyNemjOLSMSexqaSKwSf2YMqYgdQ1OHsO1DK4T4+YxKaELiLSjIYGZ8F7nzJqYAaTTx3Izj0H+fKvl9GzaxpzLszh7Y2lVNfWc8vFI3jy/a38cV0xPbumcdX4Qdxx+Wi6p6dx7oj+R86XngaD+0SvRd6YErqISDOe+dv2I10mA3t3B+BQbT3dTuzBPS+vAeC2S0/hrqvG8K2pYzhYU09G93TS0xIzgFAJXUQkTOGuA7y5voSa+gbmLy3ggpEDmH1eNn9aX0JxZTXf+fxYJgzpw7aK/RyoqWds1okAdE9Po3t67FrfraGELiIp41BdPU+9v42nl22jtt6ZMfFkvnHFqSxa9Rnl+w7x4ZYKlm78+3jwHl27cP91Exg5MIPpZ5581LlGDsyId/gtUkIXkaRX3+D87K3NPP3hNir213D+yP50T0/jv9/+hJdW7qR4bzUAmRnduePy0Vw3aQh9e3ajpr7hSFdLZ6CELiJJZ+mGUn70h3y+ekEON56bzfcWreV3H27n8rGD+F8X53DhqEzcnQeXbOT5vEJ+Nmsil48dRI+uaaR1sUSH32bm7omOQaTTy83NdW1Bl3jVtfUseO9THn5jEyd0S6Oquu7Ic7dOHsm3p41t8hp3PzJ+vKMysxXunttSPbXQRaRTK9x1gBdX7uD9ggo2llRRebCWq8YP4uGZE3krv4RPyvYztF9PvnR25N0EO3oyPx5K6CLSqRyqq2fJuhIqD9SQ1acndzy3iv01dZw5tC9Txw9mxqSTuXBUJgAzJjbevyS5KaGLSKewsbiKea+t4+PCSvYd+ntXyiknZfCbm89hWP8TEhhdx6CELiIdXl19A3c8t4riyoPMmHgyV40fzICMbizdUMqN5w2nf69uiQ6xQ1BCF5EO6Zll2/nVO5+we38NIwdmkF+0l198+SymnZ51pM74k/skMMKORxtciEiHs3zrLr776lr6ndCNK8cP5tPy/Vw5bhBTJwxOdGgdmlroItJhuDtvrC/hOy+vZVi/nvz2lnPp3aMrDQ2h4dXJNCIlFtRCl5RiZlPNbKOZFZjZ3RGezzazpWb2kZmtNrOrExFnKqqrb+A7r6zl1t+uYECvbjz61Vx69+gKQJcuRpdOPOEnXtRCl5RhZmnAfOAKYAew3MwWufv6sGr3Etpr9BdmNo7QdnU5cQ82xezeX8M3Fq7i7Y1l3Dp5JHddOYauCVqxsDNTQpdUci5Q4O5bAMzsWWAGEJ7QHTgxOO4DfBbXCFPQ+wXl3PX8x5Tvq+H+6ybw5fOGJzqkTksJXVLJEKAw7PEO4LxGdb4PvGFm/wr0Ai5v7mRmNheYC5CdnR3VQFPF/KUF/GTJRkZk9uKFr13AGUPbv69mKtPfNCJHmw084e5DgauB35pZxJ8Td3/U3XPdPXfgwPbt1p6KXlv9GT9ZspEZE09m8b9domQeBe1qoZvZVOBnQBrwa3d/4Fj1MzMzPScnpz2XFGnW1q1bKS8vP9ads53AsLDHQ4OycLcAUwHc/QMz6wFkAqXRjDXVLV5TxDcXfkzu8H48+I9nJHxjiGTR5oTeyhtMR8nJyUEr0kms5Oa2uBjdcmC0mY0glMhnATc2qrMduAx4wszGAj2AMiQq1u6s5FfvbOG11Z9xVnY/HvtqrpJ5FLWnhd6aG0wiHYa715nZbcASQn9VLnD3dWY2D8hz90XAncBjZvYNQjdIb3atMR0Vb64v4evPrKRHehduuWgEd101hh5dlcyjqT0JvTU3mHTjSDoUd19MaChieNl9YcfrgYviHVeycnd+/lYBT32wlYr9NZw5rC9P3HwO/bT2SkzEfJSLuz8KPAqhTQBifT0R6Ti+88panlm2nctOO4kLT8nkhnOGkdFdg+tipT2fbGtuMIlIinq/oJxnlm3nny8ZwT1Xj9W0/Thoz7DFIzeYzKwboRtMi6ITloh0Vgdr6qk8UMtDb2wkq08P7rxyjJJ5nLS5hd7cDaaoRSYinU5tfQPX/fd7bCiuAuCH152uG59x1K7OrEg3mEQkdT35/lY2FFdx84U59O6RzpdyI+/jKbGhuxMi0i7uzm/e28qLK3fwSdk+powZyPe+ME7dLAmgqf8i0mbuzg9ez2fea+tJT+vC1PGDuf+605XME0QtdBE5bvUNTvm+Q/zXnwv47YfbuPnCHO67ZpzWLE8wJXQROW5zn8rjrQ2h5W1unTySu6eeplZ5B6CELiLHpajyIH/eWMr0M0/mH88eyiWjM5XMOwgldBE5LotWfYY73HnlqQwf0CvR4UgYJfQoeeihh5qUHTx4MGLd1atXNyl74YUXWn2tr33ta03KLrjggoh1b7rpplafV6Q1Xv5oJ5Oy+yqZd0Aa5SIirbKqcA83Pb6MDcVVXD9pSKLDkQjUQheRY3J3fvzHjfzqnU8Y0Ks735o6htnnauXUjkgJXUSO6bnlhfzyL58wM3co371mHL17dE10SNIMJXQRadaWsn38x/+s5+JTMnng+jM0zryDUx+6pBQzm2pmG82swMzujvD8T81sVfBvk5ntSUScHYG7891X19I1zXh45plK5p2AWujH6YYbbohY/vzzz7frvMczjveXv/xlk7I//elPEetOnjy5SVmq7hzVmn1w3f0bYfX/FZgU90A7iMVrinmvoIJ5M8Yz6MQeiQ5HWkEtdEklR/bBdfca4PA+uM2ZDfw+LpF1MAWlVdzz8hrGZZ3IjboB2mkooUsqibQPbsTxd2Y2HBgB/Lm5k5nZXDPLM7O8srKyqAaaSMWV1cxZsJyuaV345VfOJj1NaaKz0P+USGSzgBfcvb65Cu7+qLvnunvuwIED4xha7OzaX8NXHl9G5cFafnPzOWQPOCHRIclxUEKXVHI8++DOIgW7W777ylq27zrAr+fkcvrQPokOR46TbooeQ6QboO29+Qlw2mmnNSmbOnVqk7ItW7ZEfP2iRU23bi0oKIhY93e/+12TsnvuuaelEJPVkX1wCSXyWcCNjSuZ2WlAP+CD+IaXWCu37+b1NUXcftlozh85INHhSBu0K6Gb2VagCqgH6tw9NxpBicRCc/vgmtk8IM/dD/+mnAU86+6eqFjj7WBNPfP+Zz2ZGd2Z+7mRiQ5H2igaLfRL3b08CucRiblI++C6+32NHn8/njElWuXBWv7pN3/j4x17+PmsSfTqrj/cOyv9z4mkMHfnnpfXsHpHJf9941lMOz0r0SFJO7T3pqgDb5jZCjObG6lCsg7tEkkGr676jNdXF/GNK05VMk8C7U3oF7v7WcA04Otm9rnGFZJxaJdIMqitb+CBP2zgzGF9+ZfJoxIdjkRBu7pc3H1n8LXUzF4mNBPvnWgEFk95eXkRy19++eVWn2PChAlNyiKNRgHIzMxsUpaRkdGkrKamJuLrzzvvvCZlH3/8ccS6FRUVEctF/rC2mOK91dx/3QTStE5LUmhzC93MeplZ78PHwJXA2mgFJiKxU11bz+N/3cLIzF5cOuakRIcjUdKeFvog4OVgUal04Bl3/2NUohKRmFm8poi7nv+YAzX1/Oj607WKYhJpc0J39y3AmVGMRUTiYPGaIk7ols4vv3I2l4xu2v0nnZeGLYqkmA3FVUwc1pfPnapBCslGCR0oKiqKWB5pomCkm58AS5YsaVKWldW+YWAPPfRQxPL8/PxWn+Oaa65pVwySXKpr6/m0fD/TJgxOdCgSA1qcSySFFJTuo77BOW3wiYkORWJACV0khWworgJgzODeCY5EYkEJXSSFbCzeS/f0LuRonfOkpIQukkI2FFdx6qDe2oUoSel/VSRF1NY3sHZnpbpbkphGuQBf+MIXIpZH2jSid+/IPwz9+/ePakwAzz33XMTy5pYEEDmWN9aVsPtArUa4JDG10EVSxBPvf8rwASdoqn8SU0IXSQHrPqtk+dbd3HT+cE31T2JK6JJSzGyqmW00swIzu7uZOjPNbL2ZrTOzZ+IdYyy8vTG0F8F1k4YkOBKJJfWhS8owszRgPnAFsANYbmaL3H19WJ3RwLeBi9x9t5klRf/Eim27GTWwFwMyuic6FIkhJfRjGD58eNyu9ZOf/KRJ2aZNm1r9+khrpB+rPEWdCxQEC8thZs8CM4D1YXX+GZjv7rshtNZ/3KOMsoYGZ8W23Uwdr5uhyU5dLpJKhgCFYY93BGXhTgVONbP3zOxDM5va3Mk6y/aKn5Tto/JgLWfn9Et0KBJjSugiR0sHRgNTgNnAY2bWN1LFzrK9Yt623QDkDldCT3ZK6JJKdgLDwh4PDcrC7QAWuXutu38KbCKU4Dut5Z/uon+vbozI7JXoUCTGlNAllSwHRpvZCDPrBswCGm/8+gqh1jlmlkmoC2ZLPIOMpsJdB3htdRGXjz2JYHcxSWJK6JIy3L0OuA1YAuQDC919nZnNM7PpQbUlQIWZrQeWAv/X3TvtTts/+kM+aV2Mb14xJtGhSBy0OMrFzBYA1wCl7j4hKOsPPAfkAFuBmYdHBUjLXnvttSZl9913X5OyQ4cORXz9oEGDmpQ98MADEeuecIJW1Qvn7ouBxY3K7gs7duCbwb9O7dPy/SxeU8wdl49mcJ8eiQ5H4qA1LfQngMZ3+u8G3nL30cBbwWMR6UDeKygH4NqJmkyUKlpM6O7+DrCrUfEM4Mng+Eng2ijHJSLt9MEnFZzcpwfDtfZ5ymhrH/ogdz+8EWcx0LQPINBZxuqKJJOGBueDLRWcP2qAboamkHbfFA36HJvupvz35zvFWF2RZLKxpIpd+2u4cFRmokOROGrr1P8SM8ty9yIzywI6/fToeMrLy2tS1twN0EhuuOGGJmWTJ09uV0ySXA73n18wakCCI5F4amsLfREwJzieA7wanXBEJBpeWbWTsVknMqRvz0SHInHUYkI3s98DHwBjzGyHmd0CPABcYWabgcuDxyLSAazdWcnanXuZfe6wlitLUmmxy8XdZzfz1GVRjkVEouC55YV0T+/CjDM1XDHVaKaoSBKprq3nlVU7ufr0LPqc0DXR4UicKaGLJJE/ri2mqrqOmbnqbklF2uAihq69NvJ8qyVLlrTq9XPmzIlY/oMf/KDNMUlyW5hXyLD+PTlvRP9EhyIJoBa6SJIo3HWA9z+p4EtnD9NG0ClKCV0kSby2OjR5WxtBpy4ldJEksWRdMacP6cOw/lq7JVUpoYskgeLKalYV7uGq8c0uqyQpQDdFo6SoqKhJ2fvvvx+xbqRp/pHWubn33nsjvj4jI+M4o5Nk92Z+CQBXjR+c4EgkkdRCF0kCb6wrZmRmL045Sb/sU5kSuqQUM5tqZhvNrMDMmmzMYmY3m1mZma0K/v3vRMR5PPYfqmPZll1cpn1DU566XCRlmFkaMB+4AtgBLDezRe6+vlHV59z9trgH2Ebvf1JBTX0Dl445KdGhSIKphS6p5FygwN23uHsN8Cyh3bc6taUbS8nonk5ujiYTpTq10KPk+uuvb1JWXl7e6td/+ctfblI2atSodsUkTQwBCsMe7wDOi1Dvi2b2OWAT8A13L4xQBzObC8wFyM7OjnKorePuLN1QysWnZNItXe2zVKfvAJGj/Q+Q4+5nAG/y971zm+gIu3FtKtlHUWU1l56m3cBECV1Sy04gfNWqoUHZEe5e4e6Hx5X+Gjg7TrG1yV82hTYLm3yq+s9FCV1Sy3JgtJmNMLNuwCxCu28dEWypeNh0ID+O8R23v2wq47TBvRncp0eiQ5EOQH3okjLcvc7MbgOWAGnAAndfZ2bzgDx3XwT8m5lNB+qAXcDNCQu4BfsP1bH8093cfFFOokORDkIJXVKKuy8GFjcquy/s+NvAt+MdV1t8uCU0XHHyqeo/l5AWE7qZLQCuAUrdfUJQ9n3gn4GyoNo9wQ9K0lu0aFHE8o8++qjV55gyZUqTsnnz5rU1JElRf1hbTK9uaeTm9Et0KNJBtKYP/QlgaoTyn7r7xOBfSiRzkY6iqrqW11cX8YUzT6Z7elqiw5EOosWE7u7vEOpLFJEO4rXVRRysrWfmOdpqTv6uPaNcbjOz1Wa2wMya/ZvPzOaaWZ6Z5ZWVlTVXTUSOw8K8QkaflMGkYX0THYp0IG1N6L8ARgETgSLg4eYqdoTJFyLJpHDXAT7avofrzxqqxbjkKG0a5eLuJYePzewx4LWoRdSBVFRUNCn74Q9/GLFuTU1Nq887ceLEJmVa41xaa/Ga0Nr715yR1UJNSTVtaqE3mnxxHbA2OuGISEsWrynSVnMSUWuGLf4emAJkmtkO4HvAFDObCDiwFbg1hjGKSKBw1wE+3lHJ3dNOS3Qo0gG1mNDdfXaE4sdjEIuItODN9aHezmkTtNWcNKW1XEQ6kaUbSxk1sBfDB/RKdCjSASmhi3QS+w7V8eGWCv7hNK2sKJFpLZdjePjhpqMx//a3v7X69ddee23Eck3zl7Z4d3M5tfXOpUro0gy10EU6iT/ll9C7ezrnaKs5aYYSukgnULq3mkUff8Y1Z2bRNU0/thKZvjNEOoFfvbOF+gbna5NPSXQo0oEpoYt0cJUHa3l62TZmTDyZ7AGaTCTN003RY3jkkUfa9fr58+dHLNc0/8Qxs6nAzwjtWPRrd3+gmXpfBF4AznH3vDiG2MS7m8uprm3gxnOzExmGdAJqoUvKMLM0YD4wDRgHzDazcRHq9QZuB5bFN8LI/rKplBN7pDNRKytKC5TQJZWcCxS4+xZ3rwGeBWZEqPf/gB8D1fEMLhJ35y+byrhk9EDSdTNUWqDvEEklQ4DCsMc7grIjzOwsYJi7vx7PwJqzobiKkr2HtG+otIoSukjAzLoAjwB3trJ+zDdveX11aKncyWOU0KVlSuiSSnYC4Xu2DQ3KDusNTADeNrOtwPnAIjPLjXSyWG/esr3iAI/9dQufPyOLQSf2iPr5JflolEsMRdogA6Br165Rv1afPn1afa3a2tqIdSsrK1t9vd27dzcp++lPf9rq1zcnLa3phsc//vGPI9Y94YTjHsK3HBhtZiMIJfJZwI2Hn3T3SiDz8GMzexu4K1GjXOa9to70LsZ3P9/kvq1IRGqhS8pw9zrgNmAJkA8sdPd1ZjbPzKYnNrqjFVdW86f8Um65ZCSD+6h1Lq2jFrqkFHdfDCxuVHZfM3WnxCOmSP64NtR3Pv3MkxMVgnRCaqGLdECL1xQzZlBvTjlJk9Ck9ZTQRTqY0r3VLN+2i2mna1ciOT6t2VN0GPAUMIjQHqKPuvvPzKw/8ByQQ2hf0Znu3vROWQo744wz4natmTNnRizPymq6M3xJSUnEus8++2xUY4qWQYMGRSy/99574xxJfLy66jPc4Zozmv7fiRxLa1rodcCd7j6O0DCurwfTpe8G3nL30cBbwWMRaQd3Z2FeIZOy+3LKSb0THY50Mi0mdHcvcveVwXEVodEBQwhNmX4yqPYkEHl7HhFptY8K97C5dB835A5rubJII8fVh25mOcAkQosWDXL3ouCpYkJdMpFeE/PZdCLJ4vm8HfTsmsbn1d0ibdDqhG5mGcCLwB3uvjf8OXd3Qv3rTcR6Np1IsnB33t5YypQxA+ndI/qTzyT5tSqhm1lXQsn8aXd/KSguMbOs4PksoDQ2IYqkhi3l+ymqrObi0ZktVxaJoDWjXAx4HMh39/AdHxYBc4AHgq+vxiTCBLr66qublL3yyisJiKRlCxcujMl5m1umoEuX1vfWTZ/edBJmbm7E5VEiuvjii1tdtzN7r6AcgItPUUKXtmnNTNGLgJuANWa2Kii7h1AiX2hmtwDbgMjj5kSkVd7dXM7Qfj3J7q9t5qRtWkzo7v4uYM08fVl0wxFJTbX1DXywpYJrzsgi9EexyPHTTFGRDuCpD7ZRVV3HVeM1O1TaTgldJMHKqg7xn29uYvKpA7UzkbSLVls8hpdeeqlJ2YMPPhixbk1NTbuutX79+iZl0ZiKf8sttzQpGz58eKtf/8UvfjFi+dixY9sckxzt2b9tZ19NHd/7wjh1t0i7qIUukmDrPtvLiMxejByolRWlfZTQRRJsQ/Fexg4+MdFhSBJQQhdJoP2H6ti26wCnDdZCXNJ+SuiSUsxsqpltNLMCM2uyQqiZ/YuZrTGzVWb2brCyaMxsKqnCHcYooUsUKKFLyjCzNGA+MA0YB8yOkLCfcffT3X0i8CDwCDG0obgKgLFZ6nKR9tMol+P0rW99K27XeuaZZ+J2rRRxLlDg7lsAzOxZQstAHxli1GjhuV40s+hctGwo2ktG93SG9O0Zy8tIilBCl1QyBCgMe7wDOK9xJTP7OvBNoBvwD82dzMzmAnMBsrOz2xRQfnEVYwb3pksXDVeU9lOXi0gj7j7f3UcB/w40u89de5eGdnc2FO1V/7lEjRK6pJKdQPhWQEODsuY8Swx34tq55yB7q+vUfy5Ro4QuqWQ5MNrMRphZN2AWoWWgjzCz0WEPPw9sjlUwG4pCN0THZamFLtGhPnRJGe5eZ2a3AUuANGCBu68zs3lAnrsvAm4zs8uBWmA3obX+YyK/KHT/dYwmFUmUKKFLSnH3xcDiRmX3hR3fHq9Y8ov3MnzACWR014+hRIe6XEQSJL+oSlP+JaqU0EUS4EBNHVsr9uuGqESVErpIAmwsDk35H6sbohJFLSZ0MxtmZkvNbL2ZrTOz24Py75vZzmDNi1Vm1nRHZRGJaFNJaISLxqBLNLXmbkwdcKe7rzSz3sAKM3szeO6n7v5Q7MITSU6bS/bRo2sXhvbThtASPa3ZJLoIKAqOq8wsn9AUahFpo82l+xg1MIM0TfmXKDquPnQzywEmAcuCotvMbLWZLTCzflGOTSRpFZTuY/RJ2qFIoqvVCd3MMoAXgTuCFel+AYwCJhJqwT/czOvmmlmemeWVlZVFIWSRzm3foTp27jnI6EHqP5foalVCN7OuhJL50+7+EoC7l7h7vbs3AI8RWpq0ifYuYCSSbD4p3QfAKO0hKlHWmlEuBjwO5Lv7I2HlWWHVrgPWRj88keSzOUjoowcpoUt0tWaUy0XATcAaM1sVlN1DaLeXiYQ2ANgK3BqTCEWSzObSKrqmGcP7a4SLRFdrRrm8C0S6Fb84QpmItGBDURWjBmaQnqZ5fRJd+o4SiaOGBmfl9t1MytagMIk+JXSRONpUWkVVdR25w5XQJfqU0EXiaPnW3QDk5iihS/QpoYvE0Yqtu8jM6E62bohKDCihi8RR3rbdnJPTj9BoYJHoUkKXlGJmU81so5kVmNndEZ7/ZrCy6Goze8vMhkfr2nsO1LBj90EmZfeN1ilFjqKELinDzNKA+cA0YByhuRTjGlX7CMh19zOAF4AHo3X9sqpDAGT16RmtU4ocRQldUsm5QIG7b3H3GuBZYEZ4BXdf6u4HgocfAkOjdfHyfTUADMjoFq1TihwlrrvTrlixotzMtgUPM4HyeF4/TvS+Eqel7pEhQGHY4x3Aeceofwvwh+aeNLO5wFyA7OzsFoOr2B9qoWdmdG+xrkhbxDWhu/uR1bnMLM/dc+N5/XjQ+0oOZvYVIBeY3Fwdd38UeBQgNzfXWzpnxeEWei+10CU24prQRRJsJzAs7PHQoOwoZnY58B1gsrsfitbFK/YdootB3xOU0CU21IcuqWQ5MNrMRphZN2AWsCi8gplNAn4FTHf30mhevHx/Df17ddMuRRIziUzojybw2rGk99VBuXsdcBuwBMgHFrr7OjObZ2bTg2o/ATKA54PNzxc1c7rjVrHvEAN6qf9cYidhXS5B/2PS0fvq2Nx9MY1WCnX3+8KOL4/VtSv21WiEi8SUulxE4qRifw0DNMJFYkgJXSROyvcd0ggXiam4J/SWpl53Jma2wMxKzWxtWFl/M3vTzDYHXzvdsnpmNszMlgZT4NeZ2e1Bead/b4lyqK6equo6MtXlIjEU14TeyqnXnckTwNRGZXcDb7n7aOCt4HFnUwfc6e7jgPOBrwf/T8nw3hJi1/7Ds0TV5SKxE+8WeotTrzsTd38H2NWoeAbwZHD8JHBtXIOKAncvcveVwXEVoREhQ0iC95YomlQk8RDvhB5p6vWQOMcQa4PcvSg4LgYGJTKY9jKzHH/r1JcAAAWSSURBVGASsIwke2/xVL4vND9JLXSJJd0UjSF3d6DFKeEdlZllAC8Cd7j73vDnOvt7i7fDLXT1oUssxTuht2rqdSdXYmZZAMHXqM42jBcz60oomT/t7i8FxUnx3hJhW8V+QAtzSWzFO6G3OPU6CSwC5gTHc4BXExhLm1hoO53HgXx3fyTsqU7/3hLhYE09Ty/bziWjM+nVXcsnSezEe7XFOjM7PPU6DVjg7uviGUM0mdnvgSlAppntAL4HPAAsNLNbgG3AzMRF2GYXATcBa8xsVVB2D8nx3uLu6WXbqNhfw+2XjU50KJLk4t5ciDT1urNy99nNPHVZXAOJMnd/F2huBalO/d4S4ckPtnL+yP7k5vRPdCiS5HRTVCSGSvZWU7jrIFeMG5zoUCQFKKGLxNBH2/cAaGNoiQsldJEY+qhwN93SujD+5BMTHYqkACV0kRj6aPsexp18It3T0xIdiqQAJXSRGKmrb2D1jj3qbpG4UUIXiZENxVVU1zYwKVuLUkp8KKFLSmlp+WYz+5yZrTSzOjP7x/Ze78pxgzhLLXSJE01bk5QRtnzzFYQWhltuZovcfX1Yte3AzcBd7b3ehCF9ePSrue09jUirKaFLKjmyfDOAmR1evvlIQnf3rcFzDYkIUKQ91OUiqSSqyzeb2VwzyzOzvLKysnYHJ9JeSugibeTuj7p7rrvnDhw4MNHhiCihS0pJheWbJYUpoUsqSYXlmyWFKaFLynD3OuDw8s35wEJ3X2dm88xsOoCZnRMshfwl4Fdm1mmXd5bUo1EuklIiLd/s7veFHS8n1BUj0umohS4ikiQstNeviLSHmZUR2sWpsUygPM7hNEexRNYZYhnu7i0OpVJCF4khM8tz9w4xXVSxRJZMsajLRUQkSSihi4gkCSV0kdh6NNEBhFEskSVNLOpDFxFJEmqhi4gkCSV0EZEkoYQuEiMt7Y4U42sPM7OlZrbezNaZ2e1B+ffNbKeZrQr+XR2neLaa2ZrgmnlBWX8ze9PMNgdfY75Xn5mNCXvvq8xsr5ndEa/PxcwWmFmpma0NK4v4OVjIz4Pvn9VmdlaL51cfukj0BbsjbSJsdyRgdqPdkWJ5/Swgy91XmllvYAVwLTAT2OfuD8UjjrB4tgK57l4eVvYgsMvdHwh+4fVz93+PY0xphFbbPA/4J+LwuZjZ54B9wFPuPiEoi/g5BL9U/hW4OojxZ+5+3rHOrxa6SGwc2R3J3WuAw7sjxYW7F7n7yuC4itBiZG3ezCNGZgBPBsdPEvqFE0+XAZ+4e6QZvjHh7u8AuxoVN/c5zCCU+N3dPwT6Br+om6WELhIbUd0dqT3MLAeYBCwLim4L/oRfEI9ujoADb5jZCjObG5QNcvei4LgYGBSnWA6bBfw+7HEiPhdo/nM47u8hJXSRJGZmGcCLwB3uvhf4BTAKmAgUAQ/HKZSL3f0sYBrw9aDr4QgP9f3Grf83WA9/OvB8UJSoz+Uo7f0clNBFYiPhuyOZWVdCyfxpd38JwN1L3L3e3RuAxwh1DcWcu+8MvpYCLwfXLTnchRB8LY1HLIFpwEp3LwniSsjnEmjuczju7yEldJHYSOjuSGZmwONAvrs/ElYe3gd7HbC28WtjEEuv4MYsZtYLuDK47iJgTlBtDvBqrGMJM5uw7pZEfC5hmvscFgFfDUa7nA9UhnXNRKRRLiIxEoxS+E8gDVjg7vfH8doXA38F1gANQfE9hBLZREJ/1m8Fbm0pSUQhlpGEWuUQ2lTnGXe/38wGAAuBbEJLD89098Y3DGMRTy9gOzDS3SuDst8Sh8/FzH4PTCG0TG4J8D3gFSJ8DsEv5f8CpgIHgH9y97xjnl8JXUQkOajLRUQkSSihi4gkCSV0EZEkoYQuIpIklNBFRJKEErqISJJQQhcRSRL/H8ltfnXDa1MyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMdfbLrKDu2g",
        "colab_type": "code",
        "outputId": "eef4cff9-7310-41da-e1f6-204073e9e0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "time: 1.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}